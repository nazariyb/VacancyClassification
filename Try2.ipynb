{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\3naza\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"}],"source":"import random as rn\n\nimport fasttext\nimport text_preprocessing as tp\n\nimport numpy as np\nfrom numpy import newaxis\n\nfrom collections import Counter\nimport sklearn\nfrom imblearn.over_sampling import RandomOverSampler\n\nimport matplotlib.pyplot as plt\n\nimport torch\ntrain_on_gpu = torch.cuda.is_available()\ntrain_on_gpu = False\nif train_on_gpu:\n    torch.cuda.current_device()\n\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"with open(\"vacancies.txt\", mode='r', encoding='utf-8') as vf:\n    vacancies = vf.readlines()\n\nwith open(\"labels.txt\", mode='r', encoding='utf-8') as lf:\n    labels = lf.readlines()"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":"labeled_data = []\nfor vacancy, label in zip(vacancies, labels):\n    labeled_data.append(vacancy + \" __label__\" + label.replace(' ', ''))\n\nrn.shuffle(labeled_data)\nsplit_index = int(len(labeled_data) * .75)\ntrain_data = '\\n'.join(labeled_data[:split_index])\nvalid_data = '\\n'.join(labeled_data[split_index:])"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"with open(\"data.train\", mode='w', encoding='utf-8') as df:\n    df.write(train_data)\nwith open(\"data.valid\", mode='w', encoding='utf-8') as df:\n    df.write(valid_data)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"# model = fasttext.train_supervised(input='data.train', epoch=30)"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":"# model.save_model(\"model_vacancies.bin\")"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"# model.test(\"data.valid\")"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":"# model.predict('10 Jul 2017 Published 4 days ago Product Manager (mobile apps) Digital Screens, LLC IT - software development Region: Kiev Website: digitalscreens.ua/ full time Job description Responsibilities: Formation of a roadmap product development plan (short-term and long-term plans); Project team management Definition and up-to-date support of the product development strategy for mobile applications Release planning; Writing TK; Identification of priority tasks, coordination of requirements for new tasks; Supervising UX / UI design processes, usability testing; Market research of competitors. Mobile product lifecycle management (from concept development to release); Requirements: Experience in launching successful iOS, Android applications (having a portfolio of completed projects that you can be proud of is an additional advantage) Experience in managing a mobile development team of 4 people or more. Understanding the mobile application development cycle Understanding the key trends and development trends of mobile applications; Experience with analytics systems (Google Analytics, etc.); Experience with Redmine, MS Excel, Project Understanding the principles of Agile methodologies Experience as a product manager of mobile products from 3 years; Experience with Fabric and Firebase')"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":"['computer',\n 'system',\n 'sql',\n 'trainee',\n 'analyst',\n 'company',\n 'consulting',\n 'region',\n 'kiev',\n 'company']"},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":"cleared = tp.clear_and_tokenize(vacancies)\ncleared[0][:10]"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":"['computer',\n 'system',\n 'sql',\n 'trainee',\n 'analyst',\n 'company',\n 'at',\n 'consulting',\n 'region',\n 'kiev']"},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":"tokens = tp.tokenize(vacancies)\ntokens[0][:10]"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":"['computer',\n 'system',\n 'sql',\n 'trainee',\n 'analyst',\n 'company',\n 'at',\n 'consulting',\n 'region',\n 'kiev']"},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":"words = tp.get_all_words(tokens)\nwords[:10]"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"corpus = ' '.join(words)\nwith open('corpus.txt', mode='w', encoding='utf-8') as cf:\n    cf.write(corpus)"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"\n"}],"source":"# model = fasttext.train_unsupervised('corpus.txt', dim=128)\nmodel = fasttext.load_model('fasttext_model')"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"model.save_model(\"fasttext_model\")"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":"['and',\n 'of',\n 'the',\n 'in',\n 'a',\n 'to',\n 'with',\n 'experience',\n 'for',\n 'development']"},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":"model.words[:10]"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":"array([-0.22876108,  0.07642055,  0.1859511 ,  0.41626796,  0.11182241,\n       -0.28945684, -0.66903186, -0.21917312, -0.14527364,  0.06512249,\n        0.26689827, -0.0183398 , -0.02297962,  0.718341  , -0.349835  ,\n        0.06574977,  0.08183116,  0.88873255, -0.17869489, -0.4375649 ,\n       -0.13618167, -0.0016635 ,  0.10165705, -0.50262934, -0.0774672 ,\n       -0.0982023 , -0.44890982,  0.16257028, -0.14164343,  0.5974602 ,\n       -0.0784402 ,  0.54712874,  0.12620166,  0.09744629,  0.16470037,\n       -0.283907  , -0.13685536, -0.51129705, -0.2705507 ,  0.34872207,\n       -0.29827207,  0.6564145 ,  0.36645138,  0.24717124,  0.07709025,\n       -0.30961856,  0.21496625, -0.30768776,  0.02405895,  0.2402943 ,\n        0.43621793, -0.24740571,  0.32947266,  0.0898559 , -0.2837158 ,\n       -0.06052554, -0.43978968,  0.38489348, -0.25158736,  0.15060748,\n       -0.20507613,  0.21857153,  0.41095582, -0.3411489 ,  0.16295013,\n       -0.0472776 , -0.35010478,  0.25204396, -0.08301147,  0.05212531,\n       -0.41757333,  0.16097495,  0.15119945, -0.23868236,  0.06629354,\n        0.08114365,  0.7496647 ,  0.37195647, -0.09521209,  0.11394096,\n        0.22174683, -0.09609532,  0.85292953, -0.49622628,  0.15298773,\n        0.58448815,  0.15416747, -0.2603848 ,  0.28195697,  0.48044798,\n       -0.5570607 ,  0.03537363, -0.23396204,  0.18086387,  0.44865304,\n       -0.10791004,  0.13781117, -0.41279465, -0.06645061, -0.11536165,\n       -0.1622153 , -0.3876992 , -0.2618906 ,  0.21709567, -0.117974  ,\n       -0.01395328, -0.1083937 ,  0.04630356, -0.15024973, -0.5801276 ,\n        0.08884123, -0.11401399, -0.1807257 ,  0.13193266,  0.04179828,\n       -0.18892017,  0.3387116 , -0.3909077 ,  0.4945118 , -0.573989  ,\n        0.02865577,  0.58555406, -0.04184717, -0.11496881,  0.07944728,\n        0.41166183,  0.7367549 , -0.40013802], dtype=float32)"},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":"model.get_word_vector('computer')"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"def pad_feature(vector, size):\n    if len(vector) > size:\n        return vector[:size]\n    vector = vector.repeat(size // len(vector) + 1, axis=0)\n    return vector[:size]"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"data = np.empty([len(vacancies), 256, 128])\nfor n, vacancy in enumerate(tokens):\n    v = np.empty([len(vacancy), 128])\n    for k, word in enumerate(vacancy):\n        v[k] = model.get_word_vector(word)\n    data[n] = pad_feature(v, 256)"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":"(3004, 256, 128)"},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":"data.shape"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":"counts_labels = Counter(labels)\nlabel_vocab = sorted(counts_labels, key=counts_labels.get, reverse=True)\nlabel_vocab_to_int = {label: ii for ii, label in enumerate(label_vocab)}\n\nlabels_ints = []\nfor label in labels:\n    labels_ints.append(label_vocab_to_int[label])\nlabels_ints = np.array(labels_ints)"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":"(3004, 32768)"},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":"view_data = np.copy(data)\nview_data = view_data.reshape(3004, 32768)\nview_data.shape"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Before: Counter({0: 679, 1: 353, 2: 349, 3: 329, 4: 242, 5: 164, 6: 154, 7: 144, 8: 129, 9: 119, 10: 81, 11: 56, 12: 48, 13: 28, 14: 28, 15: 26, 16: 23, 17: 12, 18: 10, 19: 9, 20: 8, 21: 6, 22: 4, 23: 2, 24: 1})\nAfter: Counter({4: 679, 2: 679, 3: 679, 21: 679, 16: 679, 10: 679, 9: 679, 1: 679, 0: 679, 12: 679, 17: 679, 13: 679, 8: 679, 15: 679, 19: 679, 6: 679, 11: 679, 14: 679, 23: 679, 7: 679, 5: 679, 18: 679, 20: 679, 22: 679, 24: 679})\n"}],"source":"print('Before:', Counter(labels_ints))\nros = RandomOverSampler(random_state=0)\nX_resampled, y_resampled = ros.fit_resample(view_data, labels_ints)\nprint('After:', Counter(y_resampled))"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":"labeled_data = np.array([(x, y) for x, y in zip(X_resampled, y_resampled)])\nnp.random.shuffle(labeled_data)\nX_resampled = np.array([d[0] for d in labeled_data])\ny_resampled = np.array([d[1] for d in labeled_data])"},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":"(16975, 32768)"},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":"X_resampled.shape"},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":"(16975, 256, 128)"},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":"X_resampled = X_resampled.reshape(16975, 256, 128)\nX_resampled.shape"},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Feature Shapes:\nTrain set: \t\t(13580, 256, 128) \nValidation set: \t(1697, 256, 128) \nTest set: \t\t(1698, 256, 128)\nTrain set: \t\t(13580,) \nValidation set: \t(1697,) \nTest set: \t\t(1698,)\n"}],"source":"split_frac = 0.8\n\nsplit_idx = int(len(X_resampled)*split_frac)\ntrain_x, remaining_x = X_resampled[:split_idx], X_resampled[split_idx:]\ntrain_y, remaining_y = y_resampled[:split_idx], y_resampled[split_idx:]\n\ntest_idx = int(len(remaining_x)*0.5)\nval_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\nval_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n\nprint(\"\\t\\t\\tFeature Shapes:\")\nprint(\"Train set: \\t\\t{}\".format(train_x.shape), \n      \"\\nValidation set: \\t{}\".format(val_x.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\nprint(\"Train set: \\t\\t{}\".format(train_y.shape), \n      \"\\nValidation set: \\t{}\".format(val_y.shape),\n      \"\\nTest set: \\t\\t{}\".format(test_y.shape))"},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":"train_x = train_x[:, :, :, newaxis]\nval_x = val_x[:, :, :, newaxis]\ntest_x = test_x[:, :, :, newaxis]"},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":"train_x = np.swapaxes(train_x, 2, 3)\nval_x = np.swapaxes(val_x, 2, 3)\ntest_x = np.swapaxes(test_x, 2, 3)\n\ntrain_x = np.swapaxes(train_x, 1, 2)\nval_x = np.swapaxes(val_x, 1, 2)\ntest_x = np.swapaxes(test_x, 1, 2)"},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/plain":"(13580, 1, 256, 128)"},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":"train_x.shape"},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":"train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\nvalid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\ntest_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n\nbatch_size = 35\n\n# num_train = len(train_data)\n# indices = list(range(num_train))\n# np.random.shuffle(indices)\n# split = int(np.floor(.2 * num_train))\n# train_idx, valid_idx = indices[split:], indices[:split]\n\n# train_sampler = SubsetRandomSampler(train_idx)\n# valid_sampler = SubsetRandomSampler(valid_idx)\n\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nvalid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\ntest_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Sample input size:  torch.Size([35, 1, 256, 128])\nSample input: \n tensor([[[[-4.6494e-02, -7.9022e-02,  3.7492e-01,  ...,  5.0884e-01,\n           -6.9551e-02,  9.5529e-02],\n          [ 2.3321e-01, -6.7624e-02,  6.7799e-01,  ..., -6.8913e-02,\n           -3.2566e-01,  2.2537e-01],\n          [ 1.2325e-01, -2.2405e-01,  2.8481e-01,  ..., -1.0864e-01,\n            8.9693e-02, -2.7178e-01],\n          ...,\n          [-3.8367e-01, -3.1472e-01,  1.8253e-01,  ...,  7.1883e-02,\n            5.1735e-02,  1.4164e-01],\n          [-1.7500e-01, -4.8123e-01, -6.0737e-04,  ...,  2.3758e-01,\n           -3.6451e-02, -7.3372e-03],\n          [ 2.5164e-02, -3.4555e-01, -3.7766e-01,  ...,  1.3967e-01,\n           -3.6276e-01, -1.7457e-01]]],\n\n\n        [[[ 4.1980e-02, -2.9792e-03,  6.3573e-01,  ...,  4.1209e-01,\n           -1.8550e-01,  8.0194e-02],\n          [ 3.2760e-01, -2.3437e-01,  4.0599e-01,  ...,  3.2539e-01,\n            4.4850e-01,  7.9860e-02],\n          [-1.2529e-01, -1.1289e-01,  5.3903e-01,  ...,  2.5696e-01,\n           -2.8777e-02,  1.0974e-01],\n          ...,\n          [ 1.5421e-01, -9.7490e-02, -6.4254e-02,  ...,  3.0045e-01,\n            1.9725e-01, -1.8849e-02],\n          [-2.3641e-01, -2.2993e-02,  2.1002e-01,  ...,  2.4699e-01,\n           -2.0142e-01, -8.2511e-02],\n          [-1.6786e-02,  1.2580e-01, -3.2739e-01,  ..., -1.4168e-02,\n            4.7344e-02,  1.8003e-01]]],\n\n\n        [[[ 3.6569e-01,  1.3709e-01,  3.1305e-01,  ...,  5.9978e-02,\n           -3.1869e-01,  1.1275e-01],\n          [ 3.6569e-01,  1.3709e-01,  3.1305e-01,  ...,  5.9978e-02,\n           -3.1869e-01,  1.1275e-01],\n          [ 2.5079e-01, -3.0296e-02,  4.1338e-01,  ..., -1.7531e-01,\n           -3.9557e-01,  3.4215e-02],\n          ...,\n          [-1.0049e-01, -3.1869e-01,  2.9967e-01,  ...,  3.9460e-01,\n            2.6913e-01, -1.5217e-01],\n          [-3.1301e-02, -3.1019e-01,  4.0590e-01,  ...,  5.4990e-01,\n            6.8716e-01, -2.5377e-01],\n          [-3.1301e-02, -3.1019e-01,  4.0590e-01,  ...,  5.4990e-01,\n            6.8716e-01, -2.5377e-01]]],\n\n\n        ...,\n\n\n        [[[ 3.8950e-01, -3.7459e-01,  6.8979e-01,  ...,  2.5527e-01,\n           -5.3254e-03,  1.5161e-01],\n          [ 4.8563e-01, -2.3356e-01,  1.8411e-01,  ...,  2.9069e-01,\n           -2.2857e-01, -2.8432e-02],\n          [-1.3103e-01, -3.4036e-01, -1.7980e-02,  ...,  2.5909e-01,\n           -2.2308e-01, -2.2024e-01],\n          ...,\n          [-1.2633e-01, -9.5502e-02,  7.6575e-03,  ...,  7.7913e-02,\n           -1.1987e-02, -3.1068e-01],\n          [-1.7592e-01,  1.1418e-02,  4.6908e-01,  ..., -8.7831e-02,\n            4.2275e-01, -1.2630e-02],\n          [-2.3641e-01, -2.2993e-02,  2.1002e-01,  ...,  2.4699e-01,\n           -2.0142e-01, -8.2511e-02]]],\n\n\n        [[[ 3.8950e-01, -3.7459e-01,  6.8979e-01,  ...,  2.5527e-01,\n           -5.3254e-03,  1.5161e-01],\n          [ 4.8563e-01, -2.3356e-01,  1.8411e-01,  ...,  2.9069e-01,\n           -2.2857e-01, -2.8432e-02],\n          [-1.3103e-01, -3.4036e-01, -1.7980e-02,  ...,  2.5909e-01,\n           -2.2308e-01, -2.2024e-01],\n          ...,\n          [-1.8730e-01, -1.5846e-02, -2.2265e-02,  ...,  1.5060e-03,\n           -1.5232e-01, -2.3967e-01],\n          [-2.2560e-01, -4.3852e-02, -3.5441e-01,  ...,  4.8548e-01,\n            9.7150e-02, -2.3670e-02],\n          [ 3.8486e-02, -7.2223e-02,  2.5433e-01,  ...,  1.4199e-01,\n            1.4763e-01, -1.6618e-01]]],\n\n\n        [[[ 6.7447e-02, -2.7459e-01,  9.3793e-02,  ...,  1.9117e-01,\n            3.3878e-01, -9.6622e-02],\n          [ 2.5079e-01, -3.0296e-02,  4.1338e-01,  ..., -1.7531e-01,\n           -3.9557e-01,  3.4215e-02],\n          [ 1.2325e-01, -2.2405e-01,  2.8481e-01,  ..., -1.0864e-01,\n            8.9693e-02, -2.7178e-01],\n          ...,\n          [-1.2476e-01, -2.9211e-01, -4.6873e-02,  ...,  3.8949e-01,\n           -1.0054e-02,  2.5036e-01],\n          [-2.7194e-01, -3.0573e-01,  1.4042e-01,  ...,  1.4145e-01,\n           -5.7486e-02,  5.7053e-02],\n          [ 3.6716e-01, -1.1425e-01,  1.9882e-01,  ..., -1.5197e-01,\n           -2.4159e-01, -2.1676e-01]]]], dtype=torch.float64)\n\nSample label size:  torch.Size([35])\nSample label: \n tensor([11,  0, 11, 14, 15,  7,  9,  5,  6,  8, 13,  6, 12,  5, 16, 15, 12, 20,\n         0, 18, 18,  2,  1,  5, 20,  9,  5, 11, 14,  0,  5, 20, 22,  8,  7],\n       dtype=torch.int32)\n"}],"source":"dataiter = iter(train_loader)\nsample_x, sample_y = dataiter.next()\n\nprint('Sample input size: ', sample_x.size()) # batch_size, seq_length\nprint('Sample input: \\n', sample_x)\nprint()\nprint('Sample label size: ', sample_y.size()) # batch_size\nprint('Sample label: \\n', sample_y)"},{"cell_type":"markdown","metadata":{},"source":["# CNN"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Net(\n  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv3): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=8192, out_features=4096, bias=True)\n  (fc2): Linear(in_features=4096, out_features=512, bias=True)\n  (fc3): Linear(in_features=512, out_features=25, bias=True)\n  (dropout): Dropout(p=0.25)\n)\n"}],"source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n  \n        self.conv1 = nn.Conv2d(1, 4, 3, padding=1)\n        self.conv2 = nn.Conv2d(4, 8, 3, padding=1)\n        self.conv3 = nn.Conv2d(8, 16, 3, padding=1)\n  \n        self.pool = nn.MaxPool2d(2, 2)\n  \n        self.fc1 = nn.Linear(16 * 32 * 16, 4096)\n        self.fc2 = nn.Linear(4096, 512)\n        self.fc3 = nn.Linear(512, 25)\n\n        self.dropout = nn.Dropout(0.25)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = self.pool(F.relu(self.conv3(x)))\n        \n        x = x.view(-1, 16 * 32 * 16)\n\n        x = F.relu(self.fc1(self.dropout(x)))        \n        x = F.relu(self.fc2(self.dropout(x)))        \n        x = self.fc3(self.dropout(x))\n\n        return x\n\nmodel = Net()\nprint(model)\n\nif train_on_gpu:\n    model.cuda()"},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)"},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-34-3b5b26c4714c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-32-2f2241cc2b54>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":"n_epochs = 30\n\nvalid_loss_min = np.Inf\n\nmodel.double()\n\nfor epoch in range(1, n_epochs+1):\n\n    train_loss = 0.0\n    valid_loss = 0.0\n    \n    model.train()\n    for data, target in train_loader:\n        \n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target.long())\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()*data.size(0)\n        \n    model.eval()\n    for data, target in valid_loader:\n        if target.shape != torch.Size([35]):\n            break\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        loss = criterion(output, target.long())\n        valid_loss += loss.item()*data.size(0)\n    \n    train_loss = train_loss/len(train_loader.sampler)\n    valid_loss = valid_loss/len(valid_loader.sampler)\n        \n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n        epoch, train_loss, valid_loss))\n    \n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_cnn2.pt')\n        valid_loss_min = valid_loss"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"model.load_state_dict(torch.load('model_cnn2.pt'))"},{"cell_type":"code","execution_count":0,"metadata":{},"outputs":[],"source":"test_loss = 0.0\nclass_correct = list(0. for i in range(25))\nclass_total = list(0. for i in range(25))\n\nclasses = label_vocab[:]\n\nmodel.eval()\nfor data, target in test_loader:\n    if target.shape != torch.Size([35]):\n        break\n  \n    if train_on_gpu:\n        data, target = data.cuda(), target.cuda()\n  \n    output = model(data)\n    loss = criterion(output, target.long())\n    test_loss += loss.item()*data.size(0)\n    _, pred = torch.max(output, 1)    \n    correct_tensor = pred.eq(target.long().data.view_as(pred))\n    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n  \n    for i in range(batch_size):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\ntest_loss = test_loss/len(test_loader.dataset)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(25):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            classes[i], 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}